<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />
<title>MP Launch Monitor (rVFC Debug)</title>
<style>
  :root { --bg:#0f1115; --ink:#eaeef5; --muted:#9aa4b2; --brand:#ff725c; --line:#23262d; --ok:#4cd964; }
  body { font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto; background: var(--bg); color: var(--ink); margin: 0; padding: 16px; }
  h1 { color: var(--brand); font-size: 20px; margin: 0 0 12px 0; }
  .row { display:flex; gap:10px; flex-wrap:wrap; align-items:center; margin: 10px 0; }
  button,input,select { font-size: 16px; padding: 8px 12px; border-radius: 10px; border: 1px solid var(--line); background:#12141a; color:var(--ink); }
  button.primary { background: linear-gradient(180deg,#ff725c,#e2443a); border:0; color:#fff; }
  button[disabled]{ opacity:.5; }
  #video, #canvas { width: 100%; max-width: 560px; background: #000; border: 1px solid var(--line); border-radius: 12px; display:block; }
  #canvas { margin-top: 8px; }
  .stat { background:#12141a; border:1px solid var(--line); border-radius:10px; padding:8px 12px; min-width:160px; }
  .stats { display:flex; gap:8px; flex-wrap:wrap; margin-top: 10px; }
  .mono { font-family: ui-monospace, SFMono-Regular, Menlo, monospace; }
  .status { color: var(--muted); font-size: 14px; }
  #log { white-space: pre-wrap; font-size: 12px; color: #cbd5e1; background: #0b0d12; border:1px solid var(--line); border-radius:10px; padding:10px; max-width: 560px; }
  label { display:flex; align-items:center; gap:8px; }
</style>
</head>
<body>
<h1>Motorized Precision • Launch Monitor (rVFC Debug)</h1>

<div class="row">
  <input id="file" type="file" accept="video/*" />
  <select id="markerSel" title="Calibration object">
    <option value="tray">Ball Tray (34×25 cm)</option>
    <option value="letter">Letter 8.5×11 in</option>
    <option value="a4">A4 210×297 mm</option>
    <option value="custom">Custom…</option>
  </select>
  <input id="customW" type="number" step="0.001" placeholder="W (m)" style="width:110px;display:none">
  <input id="customH" type="number" step="0.001" placeholder="D (m)" style="width:110px;display:none">
</div>
<div class="row">
  <label>Method
    <select id="method">
      <option value="auto">Auto (prefer rVFC)</option>
      <option value="rvfc">rVFC</option>
      <option value="seek">Time-stepping</option>
    </select>
  </label>
  <label>Frames <input id="numFrames" type="number" value="16" min="6" max="60" style="width:90px"></label>
  <label>Δt (seek) <input id="deltaT" type="number" value="0.00417" step="0.0005" style="width:110px"><span class="status">≈1/240</span></label>
  <label><input type="checkbox" id="debugOverlay" checked> Overlay</label>
</div>
<div class="row">
  <button id="clearBtn">Clear Points</button>
  <button id="analyzeBtn" class="primary" disabled>Analyze</button>
  <button id="previewBtn" disabled>Preview overlay</button>
</div>

<div class="status mono" id="whyDisabled">Status: OpenCV ❌ • Video ❌ • Points 0/4 • rVFC: ?</div>

<video id="video" playsinline controls></video>
<canvas id="canvas" width="1920" height="1080"></canvas>
<p class="status">Tap the 4 corners of your tray/paper on the canvas. Analyze steps through frames (video player won’t “play” during analysis), drawing the ball overlay on the canvas and logging progress below.</p>

<div class="stats">
  <div class="stat"><b>Ball Speed</b><div id="speed" class="mono">–</div></div>
  <div class="stat"><b>Launch</b><div id="launch" class="mono">–</div></div>
  <div class="stat"><b>Azimuth</b><div id="azimuth" class="mono">–</div></div>
  <div class="stat"><b>Carry (est.)</b><div id="carry" class="mono">–</div></div>
  <div class="stat"><b>Frames</b><div id="nframes" class="mono">–</div></div>
</div>

<h3 style="margin:12px 0 6px 0">Log</h3>
<div id="log" class="mono">—</div>

<script>
  // Ensure OpenCV init flag exists BEFORE loading script
  window.cvReady = false;
  window.Module = {
    onRuntimeInitialized() {
      window.cvReady = true;
      log('OpenCV ready ✅');
      maybeEnableAnalyze();
    }
  };
</script>
<script src="https://docs.opencv.org/4.x/opencv.js"></script>

<script>
const fileInput = document.getElementById('file');
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const analyzeBtn = document.getElementById('analyzeBtn');
const previewBtn = document.getElementById('previewBtn');
const clearBtn = document.getElementById('clearBtn');
const markerSel = document.getElementById('markerSel');
const customW = document.getElementById('customW');
const customH = document.getElementById('customH');
const methodSel = document.getElementById('method');
const numFramesEl = document.getElementById('numFrames');
const deltaTEl = document.getElementById('deltaT');
const debugOverlay = document.getElementById('debugOverlay');
const why = document.getElementById('whyDisabled');
const logEl = document.getElementById('log');

const out = {
  speed: document.getElementById('speed'),
  launch: document.getElementById('launch'),
  azimuth: document.getElementById('azimuth'),
  carry: document.getElementById('carry'),
  nframes: document.getElementById('nframes')
};

let clickedPts = []; // four [x,y] points
let lastCenters = []; // for preview
let lastFrames = [];  // for preview

function log(msg){ logEl.textContent = (logEl.textContent==='—'?'':logEl.textContent+'\n') + msg; logEl.scrollTop = logEl.scrollHeight; }

markerSel.onchange = () => {
  const isCustom = markerSel.value === 'custom';
  customW.style.display = isCustom ? '' : 'none';
  customH.style.display = isCustom ? '' : 'none';
  maybeEnableAnalyze();
};

fileInput.onchange = async (e) => {
  const file = e.target.files[0];
  if (!file) return;
  log('Video selected: ' + (file.name || '(blob)'));
  video.src = URL.createObjectURL(file);
  await video.play().catch(()=>{});
  video.pause();
  video.currentTime = 0.03;
  await new Promise(res => { video.onseeked = res; });
  drawFrame(); clickedPts = []; lastCenters=[]; lastFrames=[];
  maybeEnableAnalyze();
};

video.addEventListener('timeupdate', () => { drawFrame(); });

canvas.addEventListener('pointerdown', (e) => {
  const r = canvas.getBoundingClientRect();
  const x = (e.clientX - r.left) * canvas.width / r.width;
  const y = (e.clientY - r.top) * canvas.height / r.height;
  if (clickedPts.length < 4) {
    clickedPts.push([x,y]);
    drawFrame();
    log(`Point ${clickedPts.length}/4: (${x.toFixed(1)}, ${y.toFixed(1)})`);
    maybeEnableAnalyze();
  }
});

clearBtn.onclick = () => { clickedPts = []; drawFrame(); log('Cleared all points'); maybeEnableAnalyze(); };

function drawFrame(overlayDot=null) {
  const vw = video.videoWidth || 1920, vh = video.videoHeight || 1080;
  canvas.width = vw; canvas.height = vh;
  ctx.drawImage(video, 0, 0, vw, vh);
  // draw points
  ctx.save();
  ctx.fillStyle = '#ff725c'; ctx.strokeStyle = '#ff725c'; ctx.lineWidth = 3;
  clickedPts.forEach(([x,y]) => { ctx.beginPath(); ctx.arc(x,y,10,0,Math.PI*2); ctx.fill(); });
  if (clickedPts.length === 4) {
    ctx.beginPath();
    ctx.moveTo(clickedPts[0][0], clickedPts[0][1]);
    for (let i=1;i<4;i++) ctx.lineTo(clickedPts[i][0], clickedPts[i][1]);
    ctx.closePath(); ctx.stroke();
  }
  if (debugOverlay.checked && overlayDot) {
    ctx.fillStyle = '#4cd964';
    ctx.beginPath(); ctx.arc(overlayDot[0], overlayDot[1], 8, 0, Math.PI*2); ctx.fill();
  }
  ctx.restore();
}

function maybeEnableAnalyze() {
  const okCV = window.cvReady && typeof cv !== 'undefined';
  const okVid = !!video.src && (video.readyState >= 2);
  const okPts = clickedPts.length === 4;
  const hasRVFC = !!video.requestVideoFrameCallback;
  analyzeBtn.disabled = !(okCV && okVid && okPts);
  previewBtn.disabled = lastCenters.length === 0;
  why.textContent = `Status: OpenCV ${okCV ? '✅' : '❌'} • Video ${okVid ? '✅' : '❌'} • Points ${clickedPts.length}/4 • rVFC: ${hasRVFC ? '✅' : '❌'}`;
}

/* ---- Calibration geometry ---- */
function calibMeters() {
  if (markerSel.value === 'tray')   return [0.34, 0.25]; // width x depth in meters
  if (markerSel.value === 'letter') return [0.2159, 0.2794];
  if (markerSel.value === 'a4')     return [0.2100, 0.2970];
  if (markerSel.value === 'custom') {
    const w = parseFloat(customW.value||'0'); const h = parseFloat(customH.value||'0');
    if (w>0 && h>0) return [w,h];
  }
  return [0.2159, 0.2794];
}
function solveHomography(src4, dst4) {
  const src = cv.matFromArray(4,1,cv.CV_32FC2, src4.flat());
  const dst = cv.matFromArray(4,1,cv.CV_32FC2, dst4.flat());
  const H = new cv.Mat();
  cv.findHomography(src, dst, H);
  src.delete(); dst.delete();
  return H;
}
function applyH(H, pt) {
  const [u,v]=pt; const h = H.data64F||H.data32F;
  const a=h[0]*u + h[1]*v + h[2], b=h[3]*u + h[4]*v + h[5], c=h[6]*u + h[7]*v + h[8];
  return [a/c, b/c];
}

/* ---- Frame extraction (two methods) ---- */
async function extractFramesSeek(n=16, dt=1/240){
  const frames=[]; let t=video.currentTime;
  for(let i=0;i<n;i++){
    video.currentTime = t;
    await new Promise(res=>{ video.onseeked = res; });
    drawFrame();
    frames.push({img: ctx.getImageData(0,0,canvas.width,canvas.height), t, idx:i});
    why.textContent = `Sampling (seek): ${i+1}/${n}`;
    await new Promise(requestAnimationFrame);
    t += dt;
  }
  return frames;
}

async function extractFramesRVFC(n=16){
  const frames=[];
  let count=0;
  let handle=0;
  const onframe = (now, meta) => {
    try{
      drawFrame();
      frames.push({img: ctx.getImageData(0,0,canvas.width,canvas.height), t: meta.mediaTime, idx: count});
      why.textContent = `Sampling (rVFC): ${count+1}/${n}`;
      count++;
      if (count >= n) {
        video.pause();
        cancelAnimationFrame(handle);
        done();
        return;
      }
      handle = requestAnimationFrame(()=> video.requestVideoFrameCallback(onframe));
    }catch(e){
      console.error(e);
      done(e);
    }
  };
  let doneResolve, doneReject;
  const done = (err) => { err ? doneReject(err) : doneResolve(); };
  const p = new Promise((res, rej)=>{ doneResolve=res; doneReject=rej; });
  // Ensure playing (required on iOS to get rVFC callbacks)
  video.playbackRate = 0.1;
  await video.play().catch(()=>{});
  handle = requestAnimationFrame(()=> video.requestVideoFrameCallback(onframe));
  await p;
  return frames;
}

/* ---- Detection ---- */
function detectCenters(frames){
  const centers=[]; let prevGray=null;
  for(const f of frames){
    let src = cv.matFromImageData(f.img);
    let gray = new cv.Mat(); cv.cvtColor(src,gray,cv.COLOR_RGBA2GRAY);
    let work = new cv.Mat();
    if(prevGray){ cv.absdiff(gray,prevGray,work); } else { work = gray.clone(); }
    cv.GaussianBlur(work,work,new cv.Size(3,3),0);
    cv.threshold(work,work,28,255,cv.THRESH_BINARY);
    const kernel = cv.Mat.ones(3,3,cv.CV_8U); cv.morphologyEx(work,work,cv.MORPH_OPEN,kernel);
    const contours = new cv.MatVector(), hier = new cv.Mat();
    cv.findContours(work,contours,hier,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE);
    let best=null, bestScore=-1;
    for(let i=0;i<contours.size();i++){
      const c = contours.get(i); const area = cv.contourArea(c);
      if(area<12 || area>2500){ c.delete(); continue; }
      const m = cv.moments(c,true);
      let cx = m.m10/(m.m00+1e-9), cy = m.m01/(m.m00+1e-9);
      const rect = cv.boundingRect(c);
      const circ = Math.min(rect.width,rect.height)/Math.max(rect.width,rect.height);
      const score = circ + Math.min(1, area/250.0);
      if(score>bestScore){ bestScore=score; best={x:cx,y:cy,t:f.t, idx:f.idx}; }
      c.delete();
    }
    if(best) {
      centers.push(best);
      if (debugOverlay.checked) { drawFrame([best.x, best.y]); }
    }
    src.delete(); gray.delete(); work.delete(); kernel.delete(); contours.delete(); hier.delete();
    if (prevGray) prevGray.delete();
    prevGray = cv.matFromImageData(f.img); cv.cvtColor(prevGray,prevGray,cv.COLOR_RGBA2GRAY);
    why.textContent = `Detecting ball: ${f.idx+1}/${frames.length}`;
  }
  if (prevGray) prevGray.delete();
  return centers;
}

/* ---- Kinematics ---- */
function estimateCarry(v0, theta, drag=0.75){ const g=9.80665; return (v0*v0/g)*Math.sin(2*theta)*drag; }

function fitKinematics(centers, H){
  const ground = centers.map(c=>applyH(H,[c.x,c.y]).concat([c.t]));
  const i0=0, i2=Math.min(2, ground.length-1);
  if (i2 <= i0) return null;
  const dt = ground[i2][2] - ground[i0][2] || (1/240);
  const vx = (ground[i2][0]-ground[i0][0]) / dt;
  const vy = (ground[i2][1]-ground[i0][1]) / dt;
  const vxy = Math.hypot(vx,vy);
  const dy_img = centers[i2].y - centers[i0].y;
  const theta = Math.atan2(-dy_img, vxy*40); // heuristic scale
  const phi = Math.atan2(vy, vx);
  const v0 = vxy / Math.cos(theta);
  const carry_m = estimateCarry(v0, theta, 0.75);
  return { v0, theta, phi, carry_m, n: centers.length };
}

/* ---- Analyze ---- */
analyzeBtn.onclick = async () => {
  try {
    analyzeBtn.disabled = true; previewBtn.disabled = true;
    why.textContent = 'Analyzing: solving homography…';
    const [W,H] = calibMeters();
    const dst = [[0,0],[0,H],[W,H],[W,0]];
    const Hm = solveHomography(clickedPts, dst);
    log('Homography solved from 4 points → meters');

    const n = Math.max(6, Math.min(60, parseInt(numFramesEl.value||'16',10)));
    const method = methodSel.value;
    let frames;
    if (method === 'rvfc' || (method === 'auto' && !!video.requestVideoFrameCallback)) {
      frames = await extractFramesRVFC(n);
    } else {
      const dt = Math.max(1e-4, parseFloat(deltaTEl.value||'0.00417'));
      frames = await extractFramesSeek(n, dt);
    }
    log(`Extracted ${frames.length} frames via ${method}`);
    lastFrames = frames;

    const centers = detectCenters(frames);
    log(`Detections: ${centers.length} candidate ball positions`);
    lastCenters = centers.slice();
    previewBtn.disabled = centers.length > 0;

    if (centers.length < 4) {
      why.textContent = 'Could not track the ball — try brighter light, tighter framing, or change method/Δt.';
      analyzeBtn.disabled = false; return;
    }
    why.textContent = 'Fitting short-arc trajectory…';
    const kin = fitKinematics(centers, Hm);
    if (!kin) { why.textContent = 'Estimation failed.'; analyzeBtn.disabled=false; return; }

    out.speed.textContent   = `${kin.v0.toFixed(1)} m/s (${(kin.v0*2.237).toFixed(1)} mph)`;
    out.launch.textContent  = `${(kin.theta*180/Math.PI).toFixed(1)}°`;
    out.azimuth.textContent = `${(kin.phi*180/Math.PI).toFixed(1)}°`;
    out.carry.textContent   = `${kin.carry_m.toFixed(1)} m`;
    out.nframes.textContent = `${kin.n}`;
    why.textContent = 'Done ✅';
  } catch (err) {
    console.error(err);
    log('Error: ' + (err && err.message ? err.message : String(err)));
    why.textContent = 'Error during analysis.';
  } finally {
    analyzeBtn.disabled = false;
  }
};

/* ---- Preview analyzed overlay ---- */
previewBtn.onclick = async () => {
  if (!lastFrames.length || !lastCenters.length) return;
  const vw = canvas.width, vh = canvas.height;
  for(const c of lastCenters){
    // draw corresponding frame idx (best-effort; fall back to last)
    const f = lastFrames[c.idx] || lastFrames[lastFrames.length-1];
    ctx.putImageData(f.img, 0, 0);
    drawFrame([c.x, c.y]);
    await new Promise(r => setTimeout(r, 50));
  }
};

/* Keep status fresh after visibility changes (iOS Safari quirk) */
document.addEventListener('visibilitychange', ()=>{ if(!document.hidden) maybeEnableAnalyze(); });

if ('serviceWorker' in navigator) {
  try { navigator.serviceWorker.register('./sw.js'); } catch(e){}
}
</script>
</body>
</html>
